{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "420_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "idztZW1__eUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Based on the StarGAN paper and their PyTorch implementation\n",
        "# https://github.com/yunjey/stargan\n",
        "# @InProceedings{StarGAN2018,\n",
        "# author = {Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},\n",
        "# title = {StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation},\n",
        "# booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
        "# month = {June},\n",
        "# year = {2018}\n",
        "# }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "attuBJzi_gYK",
        "colab_type": "code",
        "outputId": "5934e80a-dd6a-4994-b7a1-16445ff49d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-jB4yNSOnwu",
        "colab_type": "code",
        "outputId": "41e07235-f3ae-40c9-f484-e429b85e968b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, backend\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LeakyReLU, ReLU, Conv2D, UpSampling2D, Input, Reshape, Concatenate, ZeroPadding2D, Lambda\n",
        "!pip install tensorflow_addons\n",
        "from tensorflow_addons.layers.normalizations import InstanceNormalization \n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "from functools import partial\n",
        "from google.colab import files\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "  except RuntimeError as e:\n",
        "    print(e)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.6/dist-packages (0.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /tensorflow-2.0.0/python3.6 (from tensorflow_addons) (1.13.0)\n",
            "Requirement already satisfied: tensorflow-gpu==2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_addons) (2.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.25.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.17.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.1.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.33.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (2.0.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.0.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (1.11.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (0.8.1)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /tensorflow-2.0.0/python3.6 (from tensorflow-gpu==2.0.0->tensorflow_addons) (2.0.1)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.0.0/python3.6 (from protobuf>=3.6.1->tensorflow-gpu==2.0.0->tensorflow_addons) (41.6.0)\n",
            "Requirement already satisfied: h5py in /tensorflow-2.0.0/python3.6 (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0->tensorflow_addons) (2.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /tensorflow-2.0.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (1.7.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /tensorflow-2.0.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (3.1.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tensorflow-2.0.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /tensorflow-2.0.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (0.16.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /tensorflow-2.0.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /tensorflow-2.0.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tensorflow-2.0.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (0.2.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tensorflow-2.0.0/python3.6 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /tensorflow-2.0.0/python3.6 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (0.4.8)\n",
            "Requirement already satisfied: requests>=2.0.0 in /tensorflow-2.0.0/python3.6 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (2.22.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /tensorflow-2.0.0/python3.6 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.0.0/python3.6 (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (2019.9.11)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.0.0/python3.6 (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (1.25.7)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.0.0/python3.6 (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.0.0/python3.6 (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0->tensorflow_addons) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK5ro0nr-eUi",
        "colab_type": "text"
      },
      "source": [
        "Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKsKvv-9n9zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"drive/My Drive/processed_KDEF/*.JPG\"\n",
        "\n",
        "class Config(object):\n",
        "\tnum_c = 7\n",
        "\tinput_shape = (128,128,3)\n",
        "\tbatch_size = 16\n",
        "\tnum_epochs = 100\n",
        "\td_lr = 0.0001\n",
        "\tg_lr = 0.0001\n",
        "\tbeta1 = 0.5\n",
        "\tbeta2 = 0.999\n",
        "\tdecay_lr = False\n",
        "\n",
        "\t# Weights for the classification, reconstruction, and gradient penalty losses\n",
        "\tlambda_cls = 1\n",
        "\tlambda_rec = 10\n",
        "\tlambda_gp = 10\n",
        "\n",
        "class DataLoader():\n",
        "\n",
        "\tdef __init__(self):\n",
        "\n",
        "\t\tself.dataset_name = 'faces_dataset'\n",
        "\n",
        "\t\t# emotions as described in filenames, used for creating labels\n",
        "\t\tself.emotions = ['ne', 'af', 'an', 'di', 'ha', 'sa', 'su']\n",
        "\t\t# positions as described in filenames\n",
        "\t\tself.positions = ['s.', 'fl', 'hl', 'hr', 'fr']\n",
        "\n",
        "\t\t# This is randomly permuted to create a target label\n",
        "\t\tself.emotion_label = np.array([0,1,0,0,0,0,0])\n",
        "\t\tself.position_label = np.array([0,1,0])\n",
        "\t\tself.train_data = []\n",
        "\t\tself.custom_data = []\n",
        "\t\n",
        "\t# Used to sort inputs alphabetically\n",
        "\tdef digits_in_string(self, text):\n",
        "\t\tconvert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "\t\treturn [convert(c) for c in re.split(r'(\\d+)', text)]\n",
        "\n",
        "\t# Create random target labels for a batch\n",
        "\tdef random_labels(self, batch_size):\n",
        "\t\trandom_labels = np.zeros((batch_size, 7))\n",
        "\t\tfor i in range(batch_size):\n",
        "\t\t\trandom_labels[i] = np.random.permutation(self.emotion_label)\n",
        "\t\treturn random_labels\n",
        "\t\n",
        "\t# Create a label for the image based on the emotion specified in the file name\n",
        "\tdef create_label(self, filename):\n",
        "\t\tlabels = np.zeros(7)\n",
        "\t\timg_name = filename.split('/')[-1]\n",
        "\t\t\n",
        "\t\timg_emotion = ''.join(img_name[4:6]).lower()\n",
        "\t\tlabels[0 + self.emotions.index(img_emotion)] = 1\n",
        "\n",
        "\t\treturn labels\n",
        "\n",
        "\t# Find 'num' faces with a neutral expression facing forward.\n",
        "\t# Used for testing.\n",
        "\tdef load_test_data(self, num=10):\n",
        "\t\timg_filenames = glob.glob(data_path)\n",
        "\t\tnum_found = 0\n",
        "\t\ti = 0\n",
        "\t\twhile num_found < 10:\n",
        "\t\t\timg_name = img_filenames[i].split('/')[-1]\n",
        "\t\t\temotion = ''.join(img_name[4:6]).lower()\n",
        "\t\t\tposition = ''.join(img_name[6]).lower()\n",
        "\t\t\tif emotion == 'ne' and position == 's':\n",
        "\t\t\t\timg = cv2.imread(img_filenames[i])/127.5 - 1\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\toriginal_labels = self.create_label(img_filenames[i])\n",
        "\t\t\t\t\tflip_prob = np.random.rand()\n",
        "\t\t\t\t\tif flip_prob > 0.5:\n",
        "\t\t\t\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\t\t\tself.custom_data.append([img, original_labels])\n",
        "\t\t\t\t\tnum_found += 1\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\ti += 1\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\ti += 1\n",
        "\n",
        "\tdef load_data(self, num=4900):\n",
        "\t\timg_filenames = glob.glob(data_path)\n",
        "\t\t# img_filenames.sort(key=self.digits_in_string)\n",
        "\t\t# num = len(img_filenames)\n",
        "\t\tfor i in range(num):\n",
        "\t\t\timg_name = img_filenames[i].split('/')[-1]\n",
        "\t\t\tposition = ''.join(img_name[6:8]).lower()\n",
        "\t \n",
        "\t\t\t# Exclude images with position facing completely left or right\n",
        "\t\t\tif position != 'fl' and position != 'fr':\n",
        "\n",
        "\t\t\t\t# Normalize inputs between -1 and 1\n",
        "\t\t\t\timg = cv2.imread(img_filenames[i])/127.5 - 1\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\toriginal_labels = self.create_label(img_filenames[i])\n",
        "\t\t\t\t\tflip_prob = np.random.rand()\n",
        "\t\t\t\t\t# Flip half of images for data augmentation\n",
        "\t\t\t\t\tif flip_prob > 0.5:\n",
        "\t\t\t\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\t\t\tself.train_data.append([img, original_labels])\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tcontinue\n",
        "\t \n",
        "\tdef get_loader(self, batch_size, data=None):\n",
        "\t\tif data == None:\n",
        "\t\t\tdata = self.train_data\n",
        "\t\ttotal_batches = int(len(data)//batch_size)\n",
        "\t\timg_shape, label_shape = (batch_size, 128, 128, 3), (batch_size, 7)\n",
        "\t\tbatches = []\n",
        "\n",
        "\t\t# Create batches of images and original_labels of size batch_size\n",
        "\t\tfor i in range(total_batches):\n",
        "\t\t\tbatch = data[i*batch_size:i*batch_size + batch_size]\n",
        "\t\t\timgs = []\n",
        "\t\t\toriginal_labels = []\n",
        "\t\t\ttarget_labels = []\n",
        "\t\t\tfor b in batch:\n",
        "\t\t\t\timgs.append(b[0])\n",
        "\t\t\t\toriginal_labels.append(b[1])\n",
        "\t\t\timgs = np.array(imgs)\n",
        "\t\t\toriginal_labels = np.array(original_labels)\n",
        "\t\t\tif imgs.shape == img_shape and original_labels.shape == label_shape:\n",
        "\t\t\t\tbatches.append([imgs, original_labels])\n",
        "\t\tprint('DATA LOADED\\n')\n",
        "\t\treturn batches\n",
        "\t \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWLGcY5_n7rA",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrFlvvlfOyKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model architecture as described in the StarGAN paper.\n",
        "class StarGAN():\n",
        "  def __init__(self, config):\n",
        "    self.input_shape = config.input_shape\n",
        "    self.num_epochs = config.num_epochs\n",
        "    self.num_c = config.num_c\n",
        "    self.d_lr = config.d_lr\n",
        "    self.g_lr = config.g_lr\n",
        "    self.beta1 = config.beta1\n",
        "    self.beta2 = config.beta2\n",
        "    self.lambda_cls = config.lambda_cls\n",
        "    self.lambda_rec = config.lambda_rec\n",
        "    self.lambda_gp = config.lambda_gp\n",
        "    self.batch_size = config.batch_size\n",
        "    self.decay_lr = config.decay_lr\n",
        "  \n",
        "  def build_generator(self):  \n",
        "    def conv2d(x, filters, kernel_size, strides, padding):\n",
        "      x = ZeroPadding2D(padding=padding)(x)\n",
        "      x = Conv2D(filters, kernel_size, strides, padding='valid', use_bias=False)(x)\n",
        "      x = ReLU()(x)\n",
        "      x = InstanceNormalization(axis=-1)(x)\n",
        "      return x\n",
        "    \n",
        "    def deconv2d(x, filters, kernel_size, strides, padding):\n",
        "      x = UpSampling2D(2)(x)\n",
        "      x = Conv2D(filters, kernel_size, strides, padding='same', use_bias=False)(x)\n",
        "      x = ReLU()(x)\n",
        "      x = InstanceNormalization(axis=-1)(x)\n",
        "      return x\n",
        "\n",
        "    def down_sampling(x):\n",
        "      d1 = conv2d(x, 64, 7, 1, 3)\n",
        "      d2 = conv2d(d1, 128, 4, 2, 1)\n",
        "      d3 = conv2d(d2, 256, 4, 2, 1)\n",
        "      return d3\n",
        "\n",
        "    def bottleneck(x):\n",
        "      for _ in range(6):\n",
        "        x = conv2d(x, 256, 3, 1, 1)\n",
        "      return x\n",
        "    \n",
        "    def up_sampling(x):\n",
        "      u1 = deconv2d(x, 128, 4, 1, 1)\n",
        "      u2 = deconv2d(u1, 64, 4, 1, 1)\n",
        "      return u2\n",
        "\n",
        "    def output_conv(x):\n",
        "      x = ZeroPadding2D(padding=3)(x)\n",
        "      x = Conv2D(filters=3, kernel_size=7, strides=1, padding='valid', activation='tanh', use_bias=False)(x)\n",
        "      return x\n",
        "    \n",
        "    input_img = Input(self.input_shape)\n",
        "    input_c = Input((self.num_c,))\n",
        "    c = Lambda(lambda x: backend.repeat(x, 128**2))(input_c)\n",
        "    c = Reshape(self.input_shape)(c)\n",
        "    x = Concatenate()([input_img, c])\n",
        "    down_sampled = down_sampling(input_img)\n",
        "    bottlenecked = bottleneck(down_sampled)\n",
        "    up_sampled = up_sampling(bottlenecked)\n",
        "    out = output_conv(up_sampled)\n",
        "    return Model(inputs=[input_img, input_c], outputs=out)\n",
        "\n",
        "  def build_discriminator(self):\n",
        "    def conv2d(x, filters, kernel_size, strides, padding):\n",
        "      x = ZeroPadding2D(padding=padding)(x)\n",
        "      x = Conv2D(filters, kernel_size, strides, padding='valid', use_bias=False)(x)\n",
        "      x = LeakyReLU(0.01)(x)\n",
        "      return x\n",
        "    \n",
        "    input_img = Input(self.input_shape)\n",
        "    x = input_img\n",
        "    filters = 64\n",
        "    for _ in range(6):\n",
        "      x = conv2d(x, filters, 4, 2, 1)\n",
        "      filters = filters*2\n",
        "\n",
        "    out_cls = Conv2D(self.num_c, 2, 1, padding='valid', use_bias=False)(x)\n",
        "    out_cls = Reshape((self.num_c,))(out_cls)\n",
        "    x = ZeroPadding2D(padding=1)(x)\n",
        "    out_src = Conv2D(1, 3, 1, padding='valid', use_bias=False)(x)\n",
        "    return Model(inputs=input_img, outputs=[out_src, out_cls])\n",
        "  \n",
        "  def classification_loss(self, y_expected, y_pred):\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_expected, logits=y_pred))\n",
        "\n",
        "  def reconstruction_loss(self, y_expected, y_pred):\n",
        "    return backend.mean(backend.abs(y_expected - y_pred))\n",
        "\n",
        "  def wasserstein_loss(self, y_expected, y_pred):\n",
        "    return backend.mean(y_expected*y_pred)\n",
        "  \n",
        "  # Implemented as recommended by Keras. Just organized into fewer lines.\n",
        "  # https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
        "  def gradient_penalty_loss(self, y_expected, y_pred, averaged_samples):\n",
        "    gradients_squared = backend.square(backend.gradients(y_pred, averaged_samples)[0])\n",
        "    shape = len(gradients_squared.shape)\n",
        "    gradients_squared_sum = backend.sum(gradients_squared, axis=np.arange(1, shape))\n",
        "    gradient_penalty = backend.square(1 - backend.sqrt(gradients_squared_sum))\n",
        "    return backend.mean(gradient_penalty)\n",
        "\n",
        "\n",
        "  # Returns random weighted average of two tensors.\n",
        "  def random_weighted_avg(self, real, fake, batch_size):\n",
        "    weights = backend.random_uniform((batch_size, 1, 1, 1))\n",
        "    return (weights * real) + ((1 - weights) * fake)\n",
        "\n",
        "  # Used to smooth the label in classification loss while training D\n",
        "  def smooth_y(self, y):\n",
        "    return y*backend.random_normal((self.batch_size, y.shape[1]), 1, 0.001)\n",
        "    # return y\n",
        "\n",
        "  def build_model(self):\n",
        "    self.G = self.build_generator()\n",
        "    self.D = self.build_discriminator()\n",
        "    \n",
        "    # Make D trainable and G not trainable for training of discriminator\n",
        "    for layer in self.G.layers:\n",
        "      layer.trainable = False\n",
        "    self.G.trainable = False\n",
        "    for layer in self.D.layers:\n",
        "      layer.trainable = True\n",
        "    self.D.trainable = True\n",
        "    \n",
        "    # Inputing real image into discriminator\n",
        "    x_real_D = Input(self.input_shape)\n",
        "    out_src_real_D, out_cls_real_D = self.D(x_real_D)\n",
        "    \n",
        "    ## Using G to create a fake image and putting that into the discriminator\n",
        "    # Target class to transfer G's input to\n",
        "    label_trg_D = Input((self.num_c,))\n",
        "\n",
        "    # Fake images created by G\n",
        "    x_fake_D = self.G([x_real_D, label_trg_D])\n",
        "\n",
        "    # D's output from the fake images\n",
        "    out_src_fake_D, out_cls_fake_D = self.D(x_fake_D)\n",
        "    \n",
        "    # Random weighted average of the real and fake images\n",
        "    x_hat = self.random_weighted_avg(x_real_D, x_fake_D, self.batch_size)\n",
        "\n",
        "    # D's output from the averaged input for use in calculating gradient penalty loss\n",
        "    out_src_x_hat, _ = self.D(x_hat)\n",
        "\n",
        "    # partial_gp_loss requires the averaged samples as weights but Keras will only supply \n",
        "    # y_pred and y_true for a loss function.\n",
        "    # See https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
        "    partial_gp_loss = partial(self.gradient_penalty_loss, averaged_samples=x_hat)\n",
        "    partial_gp_loss.__name__ = 'gradient_penalty'\n",
        "\n",
        "    # Smooth label\n",
        "    out_cls_real_smoothed_D = self.smooth_y(out_cls_real_D)\n",
        "\n",
        "    # Create train_D for training the discriminator with frozen generator weights\n",
        "    self.train_D = Model([x_real_D, label_trg_D], [out_src_real_D, out_cls_real_smoothed_D, out_src_fake_D, out_src_x_hat])\n",
        "    self.train_D.compile(loss=[self.wasserstein_loss, self.classification_loss, self.wasserstein_loss, partial_gp_loss],\n",
        "                         optimizer=Adam(lr=self.d_lr, beta_1=self.beta1, beta_2=self.beta2),\n",
        "                         loss_weights=[1, self.lambda_cls, 1, self.lambda_gp])\n",
        "    \n",
        "    # Now set up to train G\n",
        "    for layer in self.G.layers:\n",
        "      layer.trainable = True\n",
        "    for layer in self.D.layers:\n",
        "      layer.trainable = False\n",
        "    self.G.trainable = True\n",
        "    self.D.trainable = False\n",
        "\n",
        "    # Define inputs\n",
        "    x_real_G = Input(self.input_shape)\n",
        "    original_label_G = Input((self.num_c,))\n",
        "    target_label_G = Input((self.num_c,))\n",
        "\n",
        "    # Create fake image with G\n",
        "    x_fake_G = self.G([x_real_G, target_label_G])\n",
        "\n",
        "    # Get outputs of D from fake image\n",
        "    out_src_fake_G, out_cls_fake_G = self.D(x_fake_G)\n",
        "\n",
        "    # Pass the image through G with its original labels\n",
        "    # for calculating reconstruction loss\n",
        "    x_rec_G = self.G([x_fake_G, original_label_G])\n",
        "\n",
        "    # Create train_G for training generator with frozen discriminator weights\n",
        "    self.train_G = Model([x_real_G, original_label_G, target_label_G], [out_src_fake_G, out_cls_fake_G, x_rec_G])\n",
        "    self.train_G.compile(loss=[self.wasserstein_loss, self.classification_loss, self.reconstruction_loss],\n",
        "                         optimizer=Adam(lr=self.g_lr, beta_1=self.beta1, beta_2=self.beta2),\n",
        "                         loss_weights=[1, self.lambda_cls, self.lambda_rec])\n",
        "    \n",
        "    # Load batches of training data\n",
        "    self.training_data = DataLoader()\n",
        "    self.training_data.load_data()\n",
        "\n",
        "    for layer in self.D.layers:\n",
        "      layer.trainable = True\n",
        "    self.D.trainable = True\n",
        "\n",
        "  def smooth_label(self, y):\n",
        "    return y*np.random.normal(0.95,0.1,y.shape)\n",
        "\n",
        "  def train(self):\n",
        "    loader = self.training_data.get_loader(self.batch_size, self.training_data.train_data)\n",
        "    \n",
        "    # Discriminator labels for fake images, real images, and dummy labels for gradient penalty\n",
        "    fake_y = np.ones((self.batch_size, 2, 2, 1), dtype=np.float32)\n",
        "    real_y = -fake_y\n",
        "    dummy_y = np.zeros((self.batch_size, 2, 2, 1), dtype=np.float32)\n",
        "    num_iter = len(loader)\n",
        "    for epoch in range(self.num_epochs):\n",
        "      # Decay learning rate each epoch\n",
        "      if self.decay_lr:\n",
        "        backend.set_value(self.train_D.optimizer.lr, self.d_lr*((self.num_epochs - epoch)/(self.num_epochs)))\n",
        "        backend.set_value(self.train_G.optimizer.lr, self.g_lr*((self.num_epochs - epoch)/(self.num_epochs)))\n",
        "      print(len(loader))\n",
        "      D_losses = np.zeros((4))\n",
        "      G_losses = np.zeros((3))\n",
        "      random.shuffle(loader)\n",
        "      for i, batch in enumerate(loader):\n",
        "\n",
        "        imgs, original_labels = batch\n",
        "        target_labels = self.training_data.random_labels(self.batch_size)\n",
        "\n",
        "        # Add noise to input images\n",
        "        imgs_D = imgs + np.random.normal(0,0.005,imgs.shape)\n",
        "        \n",
        "        # Train Discriminator on every iteration.\n",
        "        D_loss = self.train_D.train_on_batch(x = [imgs_D, target_labels], y = [self.smooth_label(real_y), original_labels, self.smooth_label(fake_y), dummy_y])\n",
        "        D_losses += np.array([D_loss[1], D_loss[3], D_loss[2], D_loss[4]])\n",
        "\n",
        "        # Train Generator on every fifth iteration.\n",
        "        if (i + 1) % 5 == 0:\n",
        "          G_loss = self.train_G.train_on_batch(x = [imgs, original_labels, target_labels], y = [self.smooth_label(real_y), target_labels, imgs])\n",
        "          G_losses += np.array([G_loss[1], G_loss[3], G_loss[2]])\n",
        "          \n",
        "      print(f\"Epoch: {epoch}\")\n",
        "      print(f\"\\tMean Epoch Loss: D/loss_real = [{D_losses[0]/num_iter:.4f}], D/loss_fake = [{D_losses[1]/num_iter:.4f}], D/loss_cls =  [{D_losses[2]/num_iter:.4f}], D/loss_gp = [{D_losses[3]/num_iter:.4f}]\")\n",
        "      # if (epoch + 1) % 5 == 0:\n",
        "      print(f\"\\tMean Epoch Loss: G/loss_fake = [{G_losses[0]/num_iter:.4f}], G/loss_rec = [{G_loss[1]/num_iter:.4f}], G/loss_cls = [{G_loss[2]/num_iter:.4f}]\") \n",
        "      \n",
        "      # Save weights every five epochs\n",
        "      if (epoch + 1) % 5 == 0:\n",
        "        self.G.save_weights('drive/My Drive/G_weights.hdf5')\n",
        "        self.D.save_weights('drive/My Drive/D_weights.hdf5')\n",
        "        self.train_D.save_weights('drive/My Drive/train_D_weights.hdf5')\n",
        "        self.train_G.save_weights('drive/My Drive/train_G_weights.hdf5')\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uh7BJSE7AVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def emotion_transfer():\n",
        "  gan = StarGAN(Config())\n",
        "  # G = gan.build_generator()\n",
        "  # D = gan.build_discriminator()\n",
        "  gan.build_model()\n",
        "  gan.G.load_weights('drive/My Drive/G_weights.hdf5')\n",
        "  gan.G.trainable = False\n",
        "  loader = DataLoader()\n",
        "  loader.load_test_data()\n",
        "  batches = loader.get_loader(1, data=loader.custom_data)\n",
        "  for i in range(6):\n",
        "    x, y = batches[1]\n",
        "    # x = (1+1)*np.random.random_sample(x.shape) - 1\n",
        "    t = np.zeros(y.shape)\n",
        "    t[:,i] = 1\n",
        "    print(t, t.shape, y.shape)\n",
        "    pred = gan.G.predict([x, t])\n",
        "    cv2.imwrite(\"transfer\" + str(i) + \".png\", pred[0]*127.5 + 127.5)\n",
        "    files.download(\"transfer\" + str(i) + \".png\")\n",
        "    cv2.imwrite(\"original\" + str(i) + \".png\", x[0]*127.5 + 127.5)\n",
        "    files.download(\"original\" + str(i) + \".png\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmo82zSwqz_b",
        "colab_type": "text"
      },
      "source": [
        "Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-qmQoKMq11o",
        "colab_type": "code",
        "outputId": "fa508c4f-81b1-49aa-8f6f-8b6f8cfa5156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "train_model = True\n",
        "keep_training = False\n",
        "if train_model:\n",
        "  config = Config()\n",
        "  if keep_training:\n",
        "    gan = StarGAN(config)\n",
        "    gan.build_model()\n",
        "    gan.D.load_weights('drive/My Drive/emotion_32/D_weights.hdf5')\n",
        "    gan.G.load_weights('drive/My Drive/emotion_32/G_weights.hdf5')  \n",
        "    gan.train_D.load_weights('drive/My Drive/emotion_32/train_D_weights.hdf5')\n",
        "    gan.train_G.load_weights('drive/My Drive/emotion_32/train_G_weights.hdf5')\n",
        "    gan.train()\n",
        "  else:\n",
        "    gan = StarGAN(config)\n",
        "    gan.build_model()\n",
        "    gan.train()\n",
        "\n",
        "# emotion_transfer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATA LOADED\n",
            "\n",
            "182\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOjX9_9WUEKq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}